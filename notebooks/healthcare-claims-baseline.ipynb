{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on torch 1.9.0v, transformers 4.8.1v, datasets 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import datasets\n",
    "\n",
    "print(f\"Running on torch {torch.__version__}v, transformers {transformers.__version__}v, datasets {datasets.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from transformers import (AdamW, get_linear_schedule_with_warmup, logging, \n",
    "                          BertConfig, BertTokenizer, BertForSequenceClassification)\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 1618\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    return random_state\n",
    "\n",
    "random_state = set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"health_fact\", \"regular\")\n",
    "clear_output()\n",
    "np.unique(ds['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = (ds\n",
    "      .map(lambda x : {'label_updated': x['label'] + 1}, remove_columns=['label'])\n",
    "      .rename_column('label_updated', 'label'))\n",
    "clear_output()\n",
    "np.unique(ds['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "tokenizer = BertTokenizer.from_pretrained(cp)\n",
    "config = BertConfig.from_pretrained(cp)\n",
    "config.update({'num_labels': 5})\n",
    "model = BertForSequenceClassification.from_pretrained(cp, config=config)\n",
    "model.to(DEVICE)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'claim_id', 'date_published', 'explanation', 'fact_checkers', 'label', 'main_text', 'sources', 'subjects'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'claim_id', 'date_published', 'explanation', 'fact_checkers', 'label', 'main_text', 'sources', 'subjects'],\n",
       "        num_rows: 1235\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['claim', 'claim_id', 'date_published', 'explanation', 'fact_checkers', 'label', 'main_text', 'sources', 'subjects'],\n",
       "        num_rows: 1225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb = lb.fit(ds['train']['label'])\n",
    "ds = (ds\n",
    "      .map(lambda x : {'label_list': lb.transform([x['label']])[0]}, remove_columns=['label'])\n",
    "      .rename_column('label_list', 'label'))\n",
    "clear_output()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'token_type_ids'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'token_type_ids'],\n",
       "        num_rows: 1235\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'token_type_ids'],\n",
       "        num_rows: 1225\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 120\n",
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer.batch_encode_plus(examples[\"claim\"], truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
    "\n",
    "cols = ds[\"train\"].column_names\n",
    "cols.remove(\"label\")\n",
    "ds_enc = ds.map(tokenize_and_encode, batched=True, remove_columns=cols, num_proc=14)\n",
    "clear_output()\n",
    "ds_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'label': tensor([0., 1., 0., 0., 0.]),\n",
       " 'input_ids': tensor([    2,     6,  1920, 16719,  1920,  2442,  5405,  6896,  8659,  2037,\n",
       "          2037, 12400, 24662,  2679, 13953,  2141,  2442,  5405,  1982,  8571,\n",
       "          2141,  1927,  3360,     6,     6,  1977,  5436, 28313,    18,   244,\n",
       "          1920, 24325, 12471,  1036,  6253,  2112,   234,    62,  6132,  2052,\n",
       "          1955, 15937,    18,     6,     3,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_enc.set_format(\"torch\")\n",
    "ds_enc = (ds_enc\n",
    "          .map(lambda x : {\"float_label\": x[\"label\"].to(torch.float)}, remove_columns=[\"label\"])\n",
    "          .rename_column(\"float_label\", \"label\"))\n",
    "clear_output()\n",
    "ds_enc['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-5\n",
    "EPS = 1e-8\n",
    "EPOCHS = 3\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    for batch in val_dataloader:\n",
    "        inputs = {\n",
    "                'attention_mask': batch['attention_mask'].to(DEVICE),\n",
    "                'input_ids': batch['input_ids'].to(DEVICE),\n",
    "                'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
    "                'labels': batch['label'].to(DEVICE),\n",
    "            }\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "            loss = output.loss\n",
    "        loss_val_total += loss.item()\n",
    "    loss_val_avg = loss_val_total/len(val_dataloader) \n",
    "    return loss_val_avg\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader):\n",
    "    optimizer = AdamW(model.parameters(), lr = LR, eps = EPS)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * EPOCHS)\n",
    "    best_val_loss = 1\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss_train_total = 0\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            model.zero_grad()\n",
    "            inputs = {\n",
    "                'attention_mask': batch['attention_mask'].to(DEVICE),\n",
    "                'input_ids': batch['input_ids'].to(DEVICE),\n",
    "                'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
    "                'labels': batch['label'].to(DEVICE),\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            loss = output.loss\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        loss_train_avg = loss_train_total / len(train_dataloader)\n",
    "        loss_val_avg = evaluate(model, val_dataloader)\n",
    "        print(f'epoch:{epoch+1}/{EPOCHS} train loss={loss_train_avg}  val loss={loss_val_avg}')\n",
    "        \n",
    "        if loss_val_avg < best_val_loss:\n",
    "            best_val_loss = loss_val_avg    \n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736817e20f3b47349885baf9b6d2608e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=308.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:1/3 train loss=0.3198231649766495  val loss=0.26926768169953275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87b466521384bd48321a5b37802ec04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=308.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:2/3 train loss=0.261448670565695  val loss=0.25971671900688076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d90734e02f4fd4abb3b0650e25d5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=308.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:3/3 train loss=0.23341736807064575  val loss=0.26568962977482724\n",
      "[0.25971671900688076]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(ds_enc['train'], batch_size=32)\n",
    "val_dataloader = torch.utils.data.DataLoader(ds_enc['validation'], batch_size=32)\n",
    "train(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base model is 0.6518 and f-score is 0.6138\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "test_dataloader = torch.utils.data.DataLoader(ds_enc['test'], batch_size=32)\n",
    "for batch in test_dataloader:\n",
    "    inputs = {\n",
    "            'attention_mask': batch['attention_mask'].to(DEVICE),\n",
    "            'input_ids': batch['input_ids'].to(DEVICE),\n",
    "            'token_type_ids': batch['token_type_ids'].to(DEVICE),\n",
    "        }\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        batch_predictions = torch.argmax(output.logits, dim=1)\n",
    "        predictions.extend(batch_predictions.cpu().detach().numpy().ravel().tolist())\n",
    "\n",
    "labels = lb.inverse_transform(ds_enc['test']['label'])\n",
    "print(f\"Accuracy of base model is {accuracy_score(y_true=labels, y_pred=predictions):.4f} and f-score is {f1_score(y_true=labels, y_pred=predictions, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "pytorch38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
